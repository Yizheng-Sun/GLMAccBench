# Default Training Configuration

# Output settings
output_dir: "./results"
logging_dir: "./logs"

# Training hyperparameters
num_train_epochs: 3
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_accumulation_steps: 1

# Optimization
learning_rate: 5e-5
weight_decay: 0.01
warmup_steps: 500
lr_scheduler_type: "linear"
max_grad_norm: 1.0

# Evaluation and checkpointing
evaluation_strategy: "steps"
eval_steps: 500
save_strategy: "steps"
save_steps: 1000
save_total_limit: 2
load_best_model_at_end: true
metric_for_best_model: "eval_loss"
greater_is_better: false

# Mixed precision
fp16: false
bf16: false
gradient_checkpointing: false

# Model-specific
freeze_backbone: true
reinitialize_classifier: true
use_gradient_clipping_callback: true
gradient_clip_threshold: 10.0

# Other
seed: 42
push_to_hub: false
report_to: ["tensorboard"]
